{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing models using the low-level backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras supports two different backends to accelerate model training and evaluation using GPUs. To make the code easier to read, both backends are wrapped using the same API and all of the code in Keras is implemented using these wrappers. In case you want to extend Keras with new layer types, optimization algorithms, or cost functions, this is the way to go.\n",
    "\n",
    "Let's get the gist of it by implementing a simple classification algorithm: logistic regression. The model has two trainable parameters: a weight matrix `W` and a bias vector `b`, which are used to perform an affine projection on the input `x`. The probability that the input belongs to the positive class is given by the logistic function:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\frac{1}{1 + e^{-(Wx + b)}}\n",
    "$$\n",
    "\n",
    "and the final predicted class is the positive class if $\\hat{y} > 0.5$ and the negative class otherwise.\n",
    "\n",
    "In this tutorial, we will learn how to implement this model and learn its optimal parameters using gradient descent. That's basically what we do in deep learning (but with a lot more layers, fancier architectures, and more robust optimization algorithms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A placeholder can be seen as an \"open slot\" where you can put values later. These are used for function arguments, such as the input and output of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = K.placeholder(shape=(None, 5))\n",
    "y = K.placeholder(shape=(None, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variable, on the other hand, can be seen as an automatically-managed shared memory between the host and the GPU (when using a GPU, of course). If running on a CPU, it is just a pointer to a normal Python array.\n",
    "\n",
    "Note that we are initializing `W` with small random numbers following a Gaussian distribution, and `b` with zero (which is common practice for this type of model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = K.variable(0.01*np.random.randn(5, 1))\n",
    "b = K.variable(np.zeros(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As `variables` have actual values, we can inspect and even change them using `.get_value()` and `.set_value()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [[-0.00656898]\n",
      " [ 0.00647002]\n",
      " [-0.00780751]\n",
      " [-0.00170109]\n",
      " [ 0.00424325]]\n",
      "Initial bias: [ 0.]\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights: {}'.format(W.get_value()))\n",
    "print('Initial bias: {}'.format(b.get_value()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The backend also contains common element-wise functions and supports common Numpy notation (so remember to use K.dot for matrix multiplications!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = K.sigmoid(K.dot(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to print `y_hat`, we get something strange:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid.0\n"
     ]
    }
   ],
   "source": [
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sigmoid.0` corresponds to the name of a *node* in the graph generated by Theano (or Tensorflow, if that's the backend you are using). Since `y_hat` depends on `x` and `y`, which do not have values yet, we cannot compute any values for it.\n",
    "\n",
    "We can use backend-dependent functions to print a graph. For Theano, we can use `theano.pp` (simple) or `theano.printing.debugprint`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sigmoid(((<TensorType(float32, matrix)> \\\\dot HostFromGpu(<CudaNdarrayType(float32, matrix)>)) + HostFromGpu(<CudaNdarrayType(float32, vector)>)))'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from theano import pp\n",
    "pp(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid [id A] ''   \n",
      " |Elemwise{add,no_inplace} [id B] ''   \n",
      "   |dot [id C] ''   \n",
      "   | |<TensorType(float32, matrix)> [id D]\n",
      "   | |HostFromGpu [id E] ''   \n",
      "   |   |<CudaNdarrayType(float32, matrix)> [id F]\n",
      "   |DimShuffle{x,0} [id G] ''   \n",
      "     |HostFromGpu [id H] ''   \n",
      "       |<CudaNdarrayType(float32, vector)> [id I]\n"
     ]
    }
   ],
   "source": [
    "from theano.printing import debugprint\n",
    "debugprint(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code we wrote so far computes the output of a logistic regression model, but we still have to train it. Let's define a loss function and its gradients for each of the trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = K.mean(K.binary_crossentropy(y_hat, y))\n",
    "\n",
    "params = [W, b]\n",
    "gradients = K.gradients(loss, params)\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "# Let's compute the gradient descent updates for each of the trainable parameters\n",
    "# in our model and store it on a list of tuples in the format (parameter to update, new_value)\n",
    "updates = []\n",
    "\n",
    "for p, g in zip([W, b], gradients):\n",
    "    new_p = p - lr*g\n",
    "    updates.append((p, new_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can turn a backend *expression* into a function by calling `K.function`. We pass a list of inputs (note: it has to be a list, even if your function only has one input!), the function we want to compute, and optionally, a list of parameters that we want to be updated **after** calling the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_fn = K.function([x, y], loss, updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will convert the graph into C++ and CUDA code and compile it (when using the Theano backend - Tensorflow will to something slightly different, but the workflow in Keras is exactly the same).\n",
    "\n",
    "Now, we will generate a random dataset with 16 examples and use it to train our model using gradient descent. As the number of samples is small, gradient descent will do the trick here - but this is never the case with deep learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating dummy dataset\n",
    "X_batch = 2*np.random.randn(16, 5)\n",
    "y_batch = np.random.randint(0, 2, size=(16,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 loss: 0.6992310881614685\n",
      "Iteration 100 loss: 0.43966320157051086\n",
      "Iteration 200 loss: 0.41002073884010315\n",
      "Iteration 300 loss: 0.39073270559310913\n",
      "Iteration 400 loss: 0.37663042545318604\n",
      "Iteration 500 loss: 0.3657509684562683\n",
      "Iteration 600 loss: 0.3570306897163391\n",
      "Iteration 700 loss: 0.3498280942440033\n",
      "Iteration 800 loss: 0.34373539686203003\n",
      "Iteration 900 loss: 0.3384825587272644\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(1000):\n",
    "    iter_loss = train_fn([X_batch, y_batch])\n",
    "    if iteration % 100 == 0:\n",
    "        print('Iteration {} loss: {}'.format(iteration, iter_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final weights: [[ 0.95124745]\n",
      " [-2.10494328]\n",
      " [ 2.35118389]\n",
      " [-0.78173244]\n",
      " [-0.08810341]]\n"
     ]
    }
   ],
   "source": [
    "print('Final weights: {}'.format(W.get_value()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = K.function([x], y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = predict([X_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = (y_batch == (predictions > 0.5).astype('int')).mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.25\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
